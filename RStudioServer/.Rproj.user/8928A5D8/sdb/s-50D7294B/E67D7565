{
    "collab_server" : "",
    "contents" : "############################################################################################\n# Logistic regression on 2012 airline delay dataset showing ScaleR operation in both local #\n# and Spark compute contexts.                                                              #\n#                                                                                          #\n# Medium airline data set has 6096762 rows and 32 columns.                                 #\n############################################################################################\n\n#####################################\n# Get sample airline departure data #\n#####################################\n\n# Create a local folder for storing data temporarily.\nlocalDir <- \"/tmp/AirOnTimeCSV2012\"\ndir.create(localDir)\n\n# Download data to the tmp folder.\nremoteDir <- \"https://packages.revolutionanalytics.com/datasets/AirOnTimeCSV2012\"\ndownload.file(file.path(remoteDir, \"airOT201201.csv\"), file.path(localDir, \"airOT201201.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201202.csv\"), file.path(localDir, \"airOT201202.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201203.csv\"), file.path(localDir, \"airOT201203.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201204.csv\"), file.path(localDir, \"airOT201204.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201205.csv\"), file.path(localDir, \"airOT201205.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201206.csv\"), file.path(localDir, \"airOT201206.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201207.csv\"), file.path(localDir, \"airOT201207.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201208.csv\"), file.path(localDir, \"airOT201208.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201209.csv\"), file.path(localDir, \"airOT201209.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201210.csv\"), file.path(localDir, \"airOT201210.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201211.csv\"), file.path(localDir, \"airOT201211.csv\"))\ndownload.file(file.path(remoteDir, \"airOT201212.csv\"), file.path(localDir, \"airOT201212.csv\"))\n\n###########################################################################\n# Describe the data the script will operate on from the airline data set. #\n###########################################################################\n\n#\n# Create columnInfo object for the subset of columns we want to use.\n#\nairlineColInfo <- list(\n  DAY_OF_WEEK = list(type = \"factor\"),\n  ORIGIN = list(type = \"factor\"),\n  DEST = list(type = \"factor\"),\n  DEP_TIME = list(type = \"integer\"),\n  ARR_DEL15 = list(type = \"logical\"))\n\n# Get all the column names.\nvarNames <- names(airlineColInfo)\n\n################################\n# Run rxLogit on local data set\n################################\n\n#\n# Define a text data source in local system for the airline data\n#\nairOnTimeDataLocal <- RxTextData(localDir,\n                                 colInfo = airlineColInfo,\n                                 varsToKeep = varNames)\n\n#\n# Define the formula to use for the logistic regression (rxLogit)\n# The model will predict whether a flight will be delayed by at least 15 minutes based\n# on Origin airport and day of the week.\n#\nformula = \"ARR_DEL15 ~ ORIGIN + DAY_OF_WEEK\"\n\n#\n# Set the compute context to local.\n#\nrxSetComputeContext(\"local\")\n\n#\n# Run a logistic regression on the local airline .csv data in a local compute\n# context (edge node only).\n# \n# Operation takes ~5:50 to complete on a D4v2 edge node.\n# \nsystem.time(\n  modelLocal <- rxLogit(formula, data = airOnTimeDataLocal)\n)\n\n#\n# Display a summary of the model\n#\nsummary(modelLocal)\n\n\n#############################################################\n# Perform the same logistic regression on data in HDFS in a #\n# Spark compute context.                                    #\n#############################################################\n\n#\n# Set the HDFS (WASB) location of example data.\n#\nbigDataDirRoot <- \"/example/data\"\n\n#\n# Set directory in bigDataDirRoot to load the data.\n#\ninputDir <- file.path(bigDataDirRoot,\"AirOnTimeCSV2012\")\n\n#\n# Create the directory.\n#\nrxHadoopMakeDir(inputDir)\n\n#\n# Copy the data from source to input.\n#\nrxHadoopCopyFromLocal(localDir, bigDataDirRoot)\n\n#\n# Define reference to HDFS filesystem in the cluster\n#\nhdfsFS <- RxHdfsFileSystem()\n\n#\n# Define the text data source in HDFS.\n#\nairOnTimeData <- RxTextData(inputDir,\n                            colInfo = airlineColInfo,\n                            varsToKeep = varNames,\n                            fileSystem = hdfsFS)\n\n#\n# Start the Spark session.\n#\ncc <- rxSparkConnect(reset=TRUE)\n\n#\n# Run the logistic regression on the  airline .csv data in HDFS in a Spark compute\n# context.\n# \n# Operation takes ~1:08 to complete on 3 worker nodes.\n# \nsystem.time(\n  modelSpark <- rxLogit(formula, data = airOnTimeData)\n)\n\n#\n# Display a summary.\n#\nsummary(modelSpark)\n\n#\n# Close the connection to Spark\n#\nrxSparkDisconnect(cc)\n\n",
    "created" : 1503503642356.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2103112374",
    "id" : "E67D7565",
    "lastKnownWriteTime" : 1503513395,
    "last_content_update" : 1503513395951,
    "path" : "~/RStudioServer/01-ScaleR-Hadoop.R",
    "project_path" : "01-ScaleR-Hadoop.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}